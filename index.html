<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>My Blog</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description">
<meta property="og:type" content="website">
<meta property="og:title" content="My Blog">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="My Blog">
<meta property="og:description">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="My Blog">
<meta name="twitter:description">
  
    <link rel="alternate" href="/atom.xml" title="My Blog" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
  

</head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">My Blog</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" results="0" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://yoursite.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main">
  
    <article id="post-Hadoop之伪分布式环境的搭建" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/04/20/Hadoop之伪分布式环境的搭建/" class="article-date">
  <time datetime="2016-04-20T14:03:54.000Z" itemprop="datePublished">2016-04-20</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/04/20/Hadoop之伪分布式环境的搭建/">Hadoop之伪分布式环境的搭建</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <hr>
<h2 id="前期工具准备"><a href="#前期工具准备" class="headerlink" title="前期工具准备"></a>前期工具准备</h2><ol>
<li>jdk：jdk-7u67-linux-x64.tar.gz</li>
<li>hadoop：hadoop-2.5.0.tar.gz <a href="http://archive.apache.org/dist/hadoop/common/hadoop-2.5.0/" target="_blank" rel="external">下载地址:http://archive.apache.org/dist/hadoop/common/hadoop-2.5.0</a></li>
</ol>
<hr>
<h2 id="环境准备-root用户"><a href="#环境准备-root用户" class="headerlink" title="环境准备(root用户)"></a>环境准备(root用户)</h2><p>1.修改主机名</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vi /etc/sysconfig/network</span><br></pre></td></tr></table></figure>
<pre><code>HOSTNAME=hadoop-senior
</code></pre><p>2.创建普通用户xu （Hadoop用此用户去操作）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost /]# useradd xu</span><br><span class="line">[root@localhost /]# echo 123456 | passwd --stdin xu</span><br></pre></td></tr></table></figure>
<p>3.设置静态IP<br>    方法一：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost /]# setup</span><br></pre></td></tr></table></figure>
<p><a href="">教程另见</a></p>
<p>方法二：</p>
<p>修改/etc/sysconfig/network-scripts/ifcfg-eth0文件</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost /]# vi /etc/sysconfig/network-scripts/ifcfg-eth0</span><br></pre></td></tr></table></figure>
<p>添加内容：</p>
<pre><code>BOOTPROTO=none
IPADDR=192.168.83.138
NETMASK=255.255.255.0
GATEWAY=192.168.83.2
DNS1=218.30.118.6
DNS2=8.8.8.8
</code></pre><p>4.关闭防火墙和selinux</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost /]# service iptables stop</span><br><span class="line">[root@localhost /]# chkconfig iptables off</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost /]# vi /etc/sysconfig/selinux</span><br></pre></td></tr></table></figure>
<p>修改为</p>
<pre><code>SELINUX=disabled
</code></pre><p>5.添加hosts文件</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost /]# vi /etc/hosts</span><br></pre></td></tr></table></figure>
<pre><code>192.168.83.138      hadoop-senior
</code></pre><p>6.重启服务器</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost /]# reboot</span><br></pre></td></tr></table></figure>
<h2 id="创建目录-root用户"><a href="#创建目录-root用户" class="headerlink" title="创建目录(root用户)"></a>创建目录(root用户)</h2><p>在/opt下创建softwares目录，存放软件；创建modules目录，软件安装目录。<br>并把/opt下所有文件设置为所有用户访问权限。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost /]# mkdir /opt/softwares   </span><br><span class="line">[root@localhost /]# mkdir /opt/modules</span><br><span class="line">[root@localhost /]# chown -R xu:xu /opt/</span><br></pre></td></tr></table></figure>
<h2 id="安装jdk-root用户"><a href="#安装jdk-root用户" class="headerlink" title="安装jdk(root用户)"></a>安装jdk(root用户)</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost /]# tar -zxf /opt/softwares/jdk-7u67-linux-x64.tar.gz -C /opt/modules/  </span><br><span class="line">[root@localhost /]# chown -R xu:xu /opt/</span><br><span class="line">[root@localhost /]# vi /etc/profile</span><br></pre></td></tr></table></figure>
<p>添加</p>
<pre><code>JAVA_HOME=/opt/modules/jdk1.7.0_67
PATH=$PATH:$JAVA_HOME/bin
</code></pre><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost /]# source  /etc/profile</span><br></pre></td></tr></table></figure>
<p>如果系统自带jdk，卸载语句：    </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost /]# rpm -e --nodeps java-1.6.0-openjdk-1.6.0.0-1.50.1.11.5.el6_3.x86_64  </span><br><span class="line">[root@localhost /]# rpm -e --nodeps tzdata-java-2012j-1.el6.noarch  </span><br><span class="line">[root@localhost /]# rpm -e --nodeps java-1.7.0-openjdk-1.7.0.9-2.3.4.1.el6_3.x86_64</span><br></pre></td></tr></table></figure>
<h2 id="安装hadoop-普通用户xu"><a href="#安装hadoop-普通用户xu" class="headerlink" title="安装hadoop(普通用户xu)"></a>安装hadoop(普通用户xu)</h2><p>1.解压hadoop-2.5.0.tar.gz</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[xu@hadoop-senior 11]$ tar -zxf hadoop-2.5.0.tar.gz -C /opt/modules/</span><br></pre></td></tr></table></figure>
<p>2.修改配置 /opt/modules/hadoop-2.5.0/etc/hadoop</p>
<p><strong>hadoop-env.sh:</strong></p>
<pre><code>export JAVA_HOME=/opt/modules/jdk1.7.0_67
</code></pre><p><strong>yarn-env.sh:</strong></p>
<pre><code>export JAVA_HOME=/opt/modules/jdk1.7.0_67
</code></pre><p><strong>mapred-env.sh</strong></p>
<pre><code>export JAVA_HOME=/opt/modules/jdk1.7.0_67
</code></pre><p><strong>core-site.xml:</strong><br>自定义namenode节点，datanode节点，在/opt/modules/hadoop-2.5.0下创建data目录</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line">	&lt;property&gt;</span><br><span class="line">		&lt;name&gt;fs.defaultFS&lt;/name&gt;</span><br><span class="line">		&lt;value&gt;hdfs://hadoop-senior:8020&lt;/value&gt;</span><br><span class="line">	&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;!--自定义namenode节点，datanode节点--&gt;</span><br><span class="line">	&lt;property&gt;</span><br><span class="line"> 		 &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;</span><br><span class="line">		 &lt;value&gt;/opt/modules/hadoop-2.5.0/data&lt;/value&gt;</span><br><span class="line">  		&lt;description&gt;A base for other temporary directories.&lt;/description&gt;</span><br><span class="line">	&lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure>
<p><strong>hdfs-site.xml:</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line">	&lt;property&gt;</span><br><span class="line">		&lt;name&gt;dfs.replication&lt;/name&gt;</span><br><span class="line">		&lt;value&gt;1&lt;/value&gt;</span><br><span class="line">	&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">	&lt;property&gt;</span><br><span class="line">		&lt;name&gt;dfs.namenode.http-address&lt;/name&gt;</span><br><span class="line">		&lt;value&gt;hadoop-senior:50070&lt;/value&gt;</span><br><span class="line">	&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure>
<p>3.启动hdfs<br>hdfs第一次启动前需要格式化format，以后启动不需要再格式化。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[xu@hadoop-senior 11]$ bin/hdfs namenode -format</span><br><span class="line">[xu@hadoop-senior 11]$ sbin/hadoop-daemon.sh start namenode</span><br><span class="line">[xu@hadoop-senior 11]$ sbin/hadoop-daemon.sh start datanode</span><br></pre></td></tr></table></figure>
<p>jps    查看java进程</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[xu@hadoop-senior hadoop-2.5.0]$ jps</span><br><span class="line">12586 Jps</span><br><span class="line">8716 DataNode</span><br><span class="line">8625 NameNode</span><br></pre></td></tr></table></figure>
<p>4.测试上传文件</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[xu@hadoop-senior 11]$ bin/hdfs dfs -mkdir /input</span><br><span class="line">[xu@hadoop-senior 11]$ bin/hdfs dfs -put /etc/yum.conf /input</span><br><span class="line">[xu@hadoop-senior 11]$ bin/hdfs dfs -ls /input</span><br><span class="line">Found 1 items</span><br><span class="line">-rw-r--r--   1 xu supergroup        969 2016-04-16 07:18 /input/yum.conf</span><br></pre></td></tr></table></figure>
<p>5.修改yarn相关的配置<br>/opt/modules/hadoop-2.5.0/etc/hadoop<br>如果目录下没有mapred-site.xml，复制mapred-site.xml.template一份，并重命名为mapred-site.xml<br><strong>mapred-site.xml:</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line">	&lt;property&gt;</span><br><span class="line">		&lt;name&gt;mapreduce.framework.name&lt;/name&gt;</span><br><span class="line">		&lt;value&gt;yarn&lt;/value&gt;</span><br><span class="line">	&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">	&lt;property&gt;</span><br><span class="line">		&lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt;</span><br><span class="line">		&lt;value&gt;hadoop-senior:19888&lt;/value&gt;</span><br><span class="line">	&lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure>
<p><strong>yarn-site.xml</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line">&lt;!-- Site specific YARN configuration properties --&gt;</span><br><span class="line">	&lt;property&gt;</span><br><span class="line">		&lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;</span><br><span class="line">		&lt;value&gt;mapreduce_shuffle&lt;/value&gt;</span><br><span class="line">	&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">	&lt;property&gt;</span><br><span class="line">		&lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;</span><br><span class="line">		&lt;value&gt;hadoop-senior&lt;/value&gt;</span><br><span class="line">	&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;!--日志聚合，日志上传到HDFS--&gt;</span><br><span class="line"></span><br><span class="line">	&lt;property&gt;</span><br><span class="line">		&lt;name&gt;yarn.log-aggregation-enable&lt;/name&gt;</span><br><span class="line">		&lt;value&gt;true&lt;/value&gt;</span><br><span class="line">	&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">	&lt;property&gt;</span><br><span class="line">		&lt;name&gt;yarn.log-aggregation-enable&lt;/name&gt;</span><br><span class="line">		&lt;value&gt;86400&lt;/value&gt;</span><br><span class="line">	&lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure>
<p>6.启动yarn相关服务</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[xu@hadoop-senior 11]$ sbin/hadoop-daemon.sh start resourcemanager</span><br><span class="line">[xu@hadoop-senior 11]$ sbin/hadoop-daemon.sh start nodemanager</span><br><span class="line">[xu@hadoop-senior hadoop-2.5.0]$ jps</span><br><span class="line">8820 NodeManager</span><br><span class="line">12586 Jps</span><br><span class="line">8716 DataNode</span><br><span class="line">8625 NameNode</span><br><span class="line">8949 ResourceManager</span><br></pre></td></tr></table></figure>
<p>7.浏览器浏览<br>HDFS服务WEB UI界面<br><a href="http://192.168.83.138:50070/" target="_blank" rel="external">http://192.168.83.138:50070/</a><br>Yarn服务WEB UI界面<br><a href="http://192.168.83.138:8088/" target="_blank" rel="external">http://192.168.83.138:8088/</a></p>
<h2 id="简单MapReduce测试"><a href="#简单MapReduce测试" class="headerlink" title="简单MapReduce测试"></a>简单MapReduce测试</h2><p>使用系统自带的wordcount项目进行测试</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br></pre></td><td class="code"><pre><span class="line">[xu@hadoop-senior hadoop-2.5.0]$ bin/yarn jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.5.0.jar  wordcount /input /output</span><br><span class="line">16/04/17 20:06:07 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable</span><br><span class="line">16/04/17 20:06:08 INFO Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id</span><br><span class="line">16/04/17 20:06:08 INFO jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=</span><br><span class="line">16/04/17 20:06:09 INFO input.FileInputFormat: Total input paths to process : 1</span><br><span class="line">16/04/17 20:06:09 INFO mapreduce.JobSubmitter: number of splits:1</span><br><span class="line">16/04/17 20:06:10 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local882772325_0001</span><br><span class="line">16/04/17 20:06:10 WARN conf.Configuration: file:/opt/modules/hadoop-2.5.0/data/mapred/staging/xu882772325/.staging/job_local882772325_0001/job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.</span><br><span class="line">16/04/17 20:06:10 WARN conf.Configuration: file:/opt/modules/hadoop-2.5.0/data/mapred/staging/xu882772325/.staging/job_local882772325_0001/job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.</span><br><span class="line">16/04/17 20:06:10 WARN conf.Configuration: file:/opt/modules/hadoop-2.5.0/data/mapred/local/localRunner/xu/job_local882772325_0001/job_local882772325_0001.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.</span><br><span class="line">16/04/17 20:06:10 WARN conf.Configuration: file:/opt/modules/hadoop-2.5.0/data/mapred/local/localRunner/xu/job_local882772325_0001/job_local882772325_0001.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.</span><br><span class="line">16/04/17 20:06:10 INFO mapreduce.Job: The url to track the job: http://localhost:8080/</span><br><span class="line">16/04/17 20:06:10 INFO mapreduce.Job: Running job: job_local882772325_0001</span><br><span class="line">16/04/17 20:06:10 INFO mapred.LocalJobRunner: OutputCommitter set in config null</span><br><span class="line">16/04/17 20:06:10 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter</span><br><span class="line">16/04/17 20:06:11 INFO mapred.LocalJobRunner: Waiting for map tasks</span><br><span class="line">16/04/17 20:06:11 INFO mapred.LocalJobRunner: Starting task: attempt_local882772325_0001_m_000000_0</span><br><span class="line">16/04/17 20:06:11 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]</span><br><span class="line">16/04/17 20:06:11 INFO mapred.MapTask: Processing split: hdfs://hadoop-senior:8020/input/yum.conf:0+969</span><br><span class="line">16/04/17 20:06:11 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer</span><br><span class="line">16/04/17 20:06:11 INFO mapreduce.Job: Job job_local882772325_0001 running in uber mode : false</span><br><span class="line">16/04/17 20:06:11 INFO mapreduce.Job:  map 0% reduce 0%</span><br><span class="line">16/04/17 20:06:13 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)</span><br><span class="line">16/04/17 20:06:13 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100</span><br><span class="line">16/04/17 20:06:13 INFO mapred.MapTask: soft limit at 83886080</span><br><span class="line">16/04/17 20:06:13 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600</span><br><span class="line">16/04/17 20:06:13 INFO mapred.MapTask: kvstart = 26214396; length = 6553600</span><br><span class="line">16/04/17 20:06:13 INFO mapred.LocalJobRunner: </span><br><span class="line">16/04/17 20:06:13 INFO mapred.MapTask: Starting flush of map output</span><br><span class="line">16/04/17 20:06:13 INFO mapred.MapTask: Spilling map output</span><br><span class="line">16/04/17 20:06:13 INFO mapred.MapTask: bufstart = 0; bufend = 1469; bufvoid = 104857600</span><br><span class="line">16/04/17 20:06:13 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26213896(104855584); length = 501/6553600</span><br><span class="line">16/04/17 20:06:14 INFO mapred.MapTask: Finished spill 0</span><br><span class="line">16/04/17 20:06:14 INFO mapred.Task: Task:attempt_local882772325_0001_m_000000_0 is done. And is in the process of committing</span><br><span class="line">16/04/17 20:06:14 INFO mapred.LocalJobRunner: map</span><br><span class="line">16/04/17 20:06:14 INFO mapred.Task: Task &apos;attempt_local882772325_0001_m_000000_0&apos; done.</span><br><span class="line">16/04/17 20:06:14 INFO mapred.LocalJobRunner: Finishing task: attempt_local882772325_0001_m_000000_0</span><br><span class="line">16/04/17 20:06:14 INFO mapred.LocalJobRunner: map task executor complete.</span><br><span class="line">16/04/17 20:06:14 INFO mapred.LocalJobRunner: Waiting for reduce tasks</span><br><span class="line">16/04/17 20:06:14 INFO mapred.LocalJobRunner: Starting task: attempt_local882772325_0001_r_000000_0</span><br><span class="line">16/04/17 20:06:14 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]</span><br><span class="line">16/04/17 20:06:14 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@5f5ffad0</span><br><span class="line">16/04/17 20:06:14 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=709551680, maxSingleShuffleLimit=177387920, mergeThreshold=468304128, ioSortFactor=10, memToMemMergeOutputsThreshold=10</span><br><span class="line">16/04/17 20:06:14 INFO reduce.EventFetcher: attempt_local882772325_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events</span><br><span class="line">16/04/17 20:06:14 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local882772325_0001_m_000000_0 decomp: 1397 len: 1401 to MEMORY</span><br><span class="line">16/04/17 20:06:14 INFO mapreduce.Job:  map 100% reduce 0%</span><br><span class="line">16/04/17 20:06:14 INFO reduce.InMemoryMapOutput: Read 1397 bytes from map-output for attempt_local882772325_0001_m_000000_0</span><br><span class="line">16/04/17 20:06:14 INFO reduce.MergeManagerImpl: closeInMemoryFile -&gt; map-output of size: 1397, inMemoryMapOutputs.size() -&gt; 1, commitMemory -&gt; 0, usedMemory -&gt;1397</span><br><span class="line">16/04/17 20:06:14 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning</span><br><span class="line">16/04/17 20:06:14 INFO mapred.LocalJobRunner: 1 / 1 copied.</span><br><span class="line">16/04/17 20:06:14 INFO reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs</span><br><span class="line">16/04/17 20:06:14 INFO mapred.Merger: Merging 1 sorted segments</span><br><span class="line">16/04/17 20:06:14 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 1388 bytes</span><br><span class="line">16/04/17 20:06:14 INFO reduce.MergeManagerImpl: Merged 1 segments, 1397 bytes to disk to satisfy reduce memory limit</span><br><span class="line">16/04/17 20:06:14 INFO reduce.MergeManagerImpl: Merging 1 files, 1401 bytes from disk</span><br><span class="line">16/04/17 20:06:14 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce</span><br><span class="line">16/04/17 20:06:14 INFO mapred.Merger: Merging 1 sorted segments</span><br><span class="line">16/04/17 20:06:14 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 1388 bytes</span><br><span class="line">16/04/17 20:06:14 INFO mapred.LocalJobRunner: 1 / 1 copied.</span><br><span class="line">16/04/17 20:06:14 INFO Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords</span><br><span class="line">16/04/17 20:06:15 INFO mapred.Task: Task:attempt_local882772325_0001_r_000000_0 is done. And is in the process of committing</span><br><span class="line">16/04/17 20:06:15 INFO mapred.LocalJobRunner: 1 / 1 copied.</span><br><span class="line">16/04/17 20:06:15 INFO mapred.Task: Task attempt_local882772325_0001_r_000000_0 is allowed to commit now</span><br><span class="line">16/04/17 20:06:15 INFO output.FileOutputCommitter: Saved output of task &apos;attempt_local882772325_0001_r_000000_0&apos; to hdfs://hadoop-senior:8020/output/_temporary/0/task_local882772325_0001_r_000000</span><br><span class="line">16/04/17 20:06:15 INFO mapred.LocalJobRunner: reduce &gt; reduce</span><br><span class="line">16/04/17 20:06:15 INFO mapred.Task: Task &apos;attempt_local882772325_0001_r_000000_0&apos; done.</span><br><span class="line">16/04/17 20:06:15 INFO mapred.LocalJobRunner: Finishing task: attempt_local882772325_0001_r_000000_0</span><br><span class="line">16/04/17 20:06:15 INFO mapred.LocalJobRunner: reduce task executor complete.</span><br><span class="line">16/04/17 20:06:15 INFO mapreduce.Job:  map 100% reduce 100%</span><br><span class="line">16/04/17 20:06:15 INFO mapreduce.Job: Job job_local882772325_0001 completed successfully</span><br><span class="line">16/04/17 20:06:15 INFO mapreduce.Job: Counters: 38</span><br><span class="line">	File System Counters</span><br><span class="line">		FILE: Number of bytes read=543812</span><br><span class="line">		FILE: Number of bytes written=1022037</span><br><span class="line">		FILE: Number of read operations=0</span><br><span class="line">		FILE: Number of large read operations=0</span><br><span class="line">		FILE: Number of write operations=0</span><br><span class="line">		HDFS: Number of bytes read=1938</span><br><span class="line">		HDFS: Number of bytes written=1023</span><br><span class="line">		HDFS: Number of read operations=15</span><br><span class="line">		HDFS: Number of large read operations=0</span><br><span class="line">		HDFS: Number of write operations=4</span><br><span class="line">	Map-Reduce Framework</span><br><span class="line">		Map input records=25</span><br><span class="line">		Map output records=126</span><br><span class="line">		Map output bytes=1469</span><br><span class="line">		Map output materialized bytes=1401</span><br><span class="line">		Input split bytes=105</span><br><span class="line">		Combine input records=126</span><br><span class="line">		Combine output records=93</span><br><span class="line">		Reduce input groups=93</span><br><span class="line">		Reduce shuffle bytes=1401</span><br><span class="line">		Reduce input records=93</span><br><span class="line">		Reduce output records=93</span><br><span class="line">		Spilled Records=186</span><br><span class="line">		Shuffled Maps =1</span><br><span class="line">		Failed Shuffles=0</span><br><span class="line">		Merged Map outputs=1</span><br><span class="line">		GC time elapsed (ms)=57</span><br><span class="line">		CPU time spent (ms)=0</span><br><span class="line">		Physical memory (bytes) snapshot=0</span><br><span class="line">		Virtual memory (bytes) snapshot=0</span><br><span class="line">		Total committed heap usage (bytes)=269230080</span><br><span class="line">	Shuffle Errors</span><br><span class="line">		BAD_ID=0</span><br><span class="line">		CONNECTION=0</span><br><span class="line">		IO_ERROR=0</span><br><span class="line">		WRONG_LENGTH=0</span><br><span class="line">		WRONG_MAP=0</span><br><span class="line">		WRONG_REDUCE=0</span><br><span class="line">	File Input Format Counters </span><br><span class="line">		Bytes Read=969</span><br><span class="line">	File Output Format Counters </span><br><span class="line">		Bytes Written=1023</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[xu@hadoop-senior hadoop-2.5.0]$ bin/hdfs dfs -ls /</span><br><span class="line">16/04/17 20:13:15 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable</span><br><span class="line">Found 2 items</span><br><span class="line">drwxr-xr-x   - xu supergroup          0 2016-04-16 20:12 /input</span><br><span class="line">drwxr-xr-x   - xu supergroup          0 2016-04-17 20:06 /output</span><br></pre></td></tr></table></figure>
      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2016/04/20/Hadoop之伪分布式环境的搭建/" data-id="cinah8f3j0001n4s6xan0kl15" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-hello-world" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/04/20/hello-world/" class="article-date">
  <time datetime="2016-04-20T13:37:37.543Z" itemprop="datePublished">2016-04-20</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/04/20/hello-world/">Hello World</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>Welcome to <a href="https://hexo.io/" target="_blank" rel="external">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="external">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="external">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="external">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="external">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="external">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="external">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="external">Deployment</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2016/04/20/hello-world/" data-id="cinah8f330000n4s6sfwuvrtg" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  

</section>
        
          <aside id="sidebar">
  
    

  
    

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/04/">April 2016</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2016/04/20/Hadoop之伪分布式环境的搭建/">Hadoop之伪分布式环境的搭建</a>
          </li>
        
          <li>
            <a href="/2016/04/20/hello-world/">Hello World</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2016 Peter-xu<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>

  </div>
</body>
</html>